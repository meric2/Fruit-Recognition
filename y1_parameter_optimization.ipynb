{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file contains hyperparameter optimization for SIFT and SVC model. They are used in the first part of the project.\n",
    "The whole model training and testing process is done in SIFT_feature_matching.py file.\n",
    "\n",
    "Yontem - 1\n",
    "Feature extraction using SIFT and Bag of Visual Words (BOVW) model\n",
    "Feature extraction is done by SIFT.\n",
    "Bag of Visual Words (BOVW) model is used to represent images as histograms of visual words.\n",
    "Extracted features are then used to train a Support Vector Machine (SVM) model for image classification.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Imports\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def extract_features(image_paths, extractor):\n",
    "    features = []\n",
    "    for path in image_paths:\n",
    "        image = cv2.imread(path)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        keypoints, descriptors = extractor.detectAndCompute(gray, None)\n",
    "        if descriptors is not None:\n",
    "            features.append(descriptors)\n",
    "    return np.concatenate(features, axis=0)\n",
    "\n",
    "def create_bovw_histograms(image_paths, extractor, kmeans):\n",
    "    histograms = []\n",
    "    for path in image_paths:\n",
    "        image = cv2.imread(path)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        keypoints, descriptors = extractor.detectAndCompute(gray, None)\n",
    "        histogram = np.zeros(len(kmeans.cluster_centers_))  # Initialize histogram for each image\n",
    "        if descriptors is not None:\n",
    "            labels = kmeans.predict(descriptors)\n",
    "            for label in labels:\n",
    "                histogram[label] += 1\n",
    "        histograms.append(histogram)  # Append histogram regardless of descriptor availability\n",
    "    return np.array(histograms)\n",
    "\n",
    "def load_dataset(root_dir): # takes the folder name (class name) as label\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    label_to_id = {}\n",
    "    for idx, class_name in enumerate(os.listdir(root_dir)):\n",
    "        class_path = os.path.join(root_dir, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            label_to_id[class_name] = idx\n",
    "            for file_name in os.listdir(class_path):\n",
    "                file_path = os.path.join(class_path, file_name)\n",
    "                image_paths.append(file_path)\n",
    "                labels.append(idx)\n",
    "    return image_paths, labels, label_to_id\n",
    "\n",
    "def model_evaluation(X, y, y_pred):\n",
    "    # Match Accuracy\n",
    "    match_accuracy = np.mean(y_pred == y)\n",
    "    print('Match Accuracy:', match_accuracy)\n",
    "\n",
    "    # Matching Precision and Recall\n",
    "    precision = precision_score(y, y_pred, average='macro')\n",
    "    print('Precision:', precision)\n",
    "    recall = recall_score(y, y_pred, average='macro')\n",
    "    print('Recall:', recall)\n",
    "\n",
    "    # Feature Count\n",
    "    feature_count = X.shape[1]\n",
    "    print('Feature Count:', feature_count)\n",
    "\n",
    "    # Unique Match Ratio\n",
    "    unique_match_ratio = len(np.unique(y_pred)) / len(np.unique(y))\n",
    "    print('Unique Match Ratio:', unique_match_ratio)\n",
    "\n",
    "    return {\n",
    "        'Match Accuracy': match_accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'Feature Count': feature_count,\n",
    "        'Unique Match Ratio': unique_match_ratio\n",
    "    }\n",
    "\n",
    "def display_all_results(image_paths, predicted_labels, true_labels, label_to_id):\n",
    "    id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "    num_images = len(image_paths)\n",
    "    num_cols = 4\n",
    "    num_rows = num_images // num_cols + (1 if num_images % num_cols != 0 else 0)\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5 * num_rows))\n",
    "    for idx, path in enumerate(image_paths):\n",
    "        row = idx // num_cols\n",
    "        col = idx % num_cols\n",
    "        ax = axes[row, col] if num_rows > 1 else axes[col]\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(image)\n",
    "        pred_label = id_to_label.get(predicted_labels[idx], \"Unknown\")\n",
    "        true_label = id_to_label.get(true_labels[idx], \"Unknown\")\n",
    "        result = \"TRUE\" if predicted_labels[idx] == true_labels[idx] else \"FALSE\"\n",
    "        ax.set_title(f\"Predicted: {pred_label}, True: {true_label}\\n{result}\")\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_sample_results(image_paths, predicted_labels, true_labels, label_to_id, sample_size=10):\n",
    "    id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "    sample_size = min(sample_size, len(image_paths))\n",
    "    \n",
    "    # Randomly sample indices without replacement\n",
    "    sampled_indices = random.sample(range(len(image_paths)), sample_size)\n",
    "    \n",
    "    # Subset the data\n",
    "    sampled_image_paths = [image_paths[i] for i in sampled_indices]\n",
    "    sampled_predicted_labels = [predicted_labels[i] for i in sampled_indices]\n",
    "    sampled_true_labels = [true_labels[i] for i in sampled_indices]\n",
    "    \n",
    "    num_cols = 4\n",
    "    num_rows = sample_size // num_cols + (1 if sample_size % num_cols != 0 else 0)\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5 * num_rows), squeeze=False)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, path in enumerate(sampled_image_paths):\n",
    "        ax = axes[idx]\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        ax.imshow(image)\n",
    "        pred_label = id_to_label.get(sampled_predicted_labels[idx], \"Unknown\")\n",
    "        true_label = id_to_label.get(sampled_true_labels[idx], \"Unknown\")\n",
    "        result = \"TRUE\" if sampled_predicted_labels[idx] == sampled_true_labels[idx] else \"FALSE\"\n",
    "        ax.set_title(f\"Predicted: {pred_label}, True: {true_label}\\n{result}\")\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Hide any unused subplot areas\n",
    "    for idx in range(len(sampled_image_paths), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_clusters = 30\n",
    "root_dir_train = 'data_128x128/train'\n",
    "root_dir_test = 'data_128x128/test'\n",
    "root_dir_val = 'data_128x128/validation'\n",
    "\n",
    "# Load datasets\n",
    "image_paths_train, labels_train, label_to_id_train = load_dataset(root_dir_train)\n",
    "image_paths_test, labels_test, label_to_id_test = load_dataset(root_dir_test)\n",
    "image_paths_val, labels_val, label_to_id_val = load_dataset(root_dir_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 344\n",
      "Best settings: {'nfeatures': 0, 'nOctaveLayers': 5, 'contrastThreshold': 0.04, 'edgeThreshold': 10, 'sigma': 1.2, 'image': array([[126, 130,  77, ...,  36,  22,  49],\n",
      "       [ 99, 135, 111, ...,  26,  20,  20],\n",
      "       [ 31, 137, 141, ...,  75,  48,  46],\n",
      "       ...,\n",
      "       [127, 135,  76, ...,  86, 163, 115],\n",
      "       [148, 161, 105, ..., 128, 159,  74],\n",
      "       [171, 145, 135, ..., 114,  88,  59]], dtype=uint8)}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "Parameter Optimization for SIFT\n",
    "Checks for the best settings for SIFT in training images\n",
    "\n",
    "\"\"\"\n",
    "train_folder = root_dir_train\n",
    "\n",
    "# Ranges for parameters to optimize\n",
    "nfeatures_range = [0, 50, 100, 200]\n",
    "nOctaveLayers_range = [3, 4, 5]\n",
    "contrastThreshold_range = [0.04, 0.1, 0.2]\n",
    "edgeThreshold_range = [10, 15, 20]\n",
    "sigma_range = [1.2, 1.6, 2.0]\n",
    "\n",
    "best_score = 0\n",
    "best_settings = {}\n",
    "\n",
    "# Loop through each class in the train folder\n",
    "for class_folder in os.listdir(train_folder):\n",
    "    class_path = os.path.join(train_folder, class_folder)\n",
    "    \n",
    "    # List the images in the class folder\n",
    "    images = os.listdir(class_path)\n",
    "\n",
    "    for image in images:\n",
    "        if image.endswith('.jpg'):\n",
    "            image_path = os.path.join(class_path, image)\n",
    "            image = cv2.imread(image_path, 0)\n",
    "\n",
    "            # Search for each image\n",
    "            for nfeatures in nfeatures_range:\n",
    "                for nOctaveLayers in nOctaveLayers_range:\n",
    "                    for contrastThreshold in contrastThreshold_range:\n",
    "                        for edgeThreshold in edgeThreshold_range:\n",
    "                            for sigma in sigma_range:\n",
    "                                # Create SIFT with current settings\n",
    "                                sift = cv2.SIFT_create(nfeatures=nfeatures, nOctaveLayers=nOctaveLayers,\n",
    "                                                    contrastThreshold=contrastThreshold, edgeThreshold=edgeThreshold,\n",
    "                                                    sigma=sigma)\n",
    "\n",
    "                                # Detect features\n",
    "                                keypoints = sift.detect(image, None)\n",
    "\n",
    "                                # Use the number of detected keypoints as the score\n",
    "                                score = len(keypoints)\n",
    "\n",
    "                                # Update best score and settings if current score is better\n",
    "                                if score > best_score:\n",
    "                                    best_score = score\n",
    "                                    best_settings = {\n",
    "                                        'nfeatures': nfeatures,\n",
    "                                        'nOctaveLayers': nOctaveLayers,\n",
    "                                        'contrastThreshold': contrastThreshold,\n",
    "                                        'edgeThreshold': edgeThreshold,\n",
    "                                        'sigma': sigma,\n",
    "                                        'image': image\n",
    "                                    }\n",
    "\n",
    "# Best settings for SIFT \n",
    "print(\"Best score:\", best_score)\n",
    "print(\"Best settings:\", best_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Emre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SIFT feature extractor and KMeans clustering model creation\n",
    "sift = cv2.SIFT_create()\n",
    "features_train = extract_features(image_paths_train, sift)\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "kmeans.fit(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BOVW histograms for train, test, and validation sets\n",
    "bovw_histograms_train = create_bovw_histograms(image_paths_train, sift, kmeans)\n",
    "bovw_histograms_test = create_bovw_histograms(image_paths_test, sift, kmeans)\n",
    "bovw_histograms_val = create_bovw_histograms(image_paths_val, sift, kmeans)\n",
    "\n",
    "# Train, test, and validation data split\n",
    "X_train, y_train = bovw_histograms_train, labels_train\n",
    "X_test, y_test = bovw_histograms_test, labels_test\n",
    "X_val, y_val = bovw_histograms_val, labels_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best Parameters: {'svc__C': 10, 'svc__gamma': 'scale', 'svc__kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy: 0.19276190476190477\n",
      "Model Evaluation on Test Set after Hyperparameter Tuning\n",
      "Match Accuracy: 0.069\n",
      "Precision: 0.067575152463602\n",
      "Recall: 0.046000000000000006\n",
      "Feature Count: 100\n",
      "Unique Match Ratio: 1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Emre\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "Parameter Optimization for SVC\n",
    "Checks for the best parameters for SVC in training images\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "param_grid = {\n",
    "    'svc__C': [0.1, 1, 10, 100],\n",
    "    'svc__kernel': ['linear', 'rbf'],\n",
    "    'svc__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler(), SVC())\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters found during grid search for SVC\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Best cross-validation accuracy\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "print(\"Model Evaluation on Test Set after Hyperparameter Tuning\")\n",
    "test_evaluation_after_tuning = model_evaluation(X_test, y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
